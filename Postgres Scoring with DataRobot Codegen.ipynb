{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Deploy a DataRobot Codegen Model to Postgres via PL/JAVA\n",
    "\n",
    "## Why?\n",
    "\n",
    "* Postgres is a popular database (and personal favorite).  It is the second most beloved database (after Redis) and is the 3rd most commonly used database based on a 2018 [survey](https://insights.stackoverflow.com/survey/2018/#technology-most-loved-dreaded-and-wanted-databases). \n",
    "\n",
    "* [Greemplum](https://greenplum.org/) is an open-source massively parrallel data platform for analytics, machine learning and AI based on Postgres.  Greenplumâ€™s massively parallel processing architecture provides automatic parallelization of all data and queries in a scale-out, shared nothing architecture.  Pivotal Greenplum is part of a larger offering from Pivotal.io.  \n",
    "* Pivotal have a lot of [logos](https://pivotal.io/customers) that overlap with DataRobot.  \n",
    "\n",
    "## PL/JAVA\n",
    "\n",
    "[PL/Java](https://github.com/tada/pljava) is a free open-source extension for PostgreSQL that allows stored procedures, triggers, and functions to be written in the Java language and executed in the backend. \n",
    "\n",
    "## Considerations\n",
    "\n",
    "### How to interact with model?  \n",
    "\n",
    "* Batch scoring\n",
    "* Online scoring via database calls\n",
    "* Ad Hoc Analysis \n",
    "\n",
    "### My requirements \n",
    "\n",
    "My main requirement was the make it feel very sql-ish, so I wrote a function that would be parameterized by the features of the model, with the end goal of running something like \n",
    "\n",
    "```\n",
    "select score(feature1, feature2, ...)\n",
    "from data_table;\n",
    "```\n",
    "\n",
    "Secondary requirement was a function to do batch scoring.  This was accomplish by creating a funciton that took as argument a string, which references a table containing the a dataset to score.  Results are returned accordingly.  For instances of more than one available model, parameterize with model id (corresponding to scoring jar) and deployment detail for mlops agents.  \n",
    "\n",
    "Example of call\n",
    "```\n",
    "create table for_scoring as \n",
    "select * from data_table limit 100;\n",
    "\n",
    "select * from batchScore('for_scoring');\n",
    "```\n",
    "\n",
    "MLOps agents can easily be introduced into both scoring methods as is, but as one moves over to a distributed system like greenplum, mlops listeners will probably need to be running in each node of cluster.  Furthermore, I'm not sure that batch scoring routine will be effective on a distributed system (more research is required).\n",
    "\n",
    "## Performance\n",
    "\n",
    "Not rigorously tested, but seems to be on par with straight scoring via a java app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Downloaded codegen model from DataRobot and published to local maven repository and write java app - comeback to this later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching over to Postgres\n",
    "\n",
    "To be able to use our functions in Postgres, we should package it up and expose it to Postgres.  \n",
    "\n",
    "This was all accomplished by rewritting the code above in Java, setting up the pom.xml and packaging the app with maven.\n",
    "\n",
    "Everything that follows is based on the Lending Club dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "select * from lending_club limit 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Jars to PLJAVA Classpath\n",
    "\n",
    "via `SET` in postgres, I add all necessary jars.  This is not exactly how it is intended to be used, but I ran into issues with the PLJAVA classloader and found the solution below works as desired.  Alternatively, classpath can be defined in the postgres config.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql \n",
    "SET pljava.classpath TO '/Users/timothy.whittaker/Desktop/pljava/pljava-1_5_2/pljava/target/pljava-1.5.2.jar:/Users/timothy.whittaker/Downloads/postgresql-42.2.9.jar:/Users/timothy.whittaker/Desktop/sbt-projects/dr-gp-scoring/lib/5d5da72a3fa59e2850f824fc.jar:/Users/timothy.whittaker/Desktop/datarobot-mlops-agent-0.1.0/lib/agent-5.3.0.jar:/Users/timothy.whittaker/Desktop/datarobot-mlops-agent-5.3.0/lib/datarobot-mlops-0.1.0.jar:/Users/timothy.whittaker/Desktop/sbt-projects/dr-gp-scoring/target/postgres-scoring-0.1.0.jar';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SQL Functions\n",
    "\n",
    "For every function we create in Java, we annotate said function with `@Function` provided by PLJava.  This annotation tells the PLJAVA that the functions are meant to be used in postgres, PLJAVA will create a PLJAVA.drr file that contains the syntax needed to deploy functions in postgres.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `modelId` function\n",
    "\n",
    "The `modelId` function is just a means to return the model id.  Other functions would be introduced based on requirements."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "CREATE OR REPLACE FUNCTION modelId()\n",
    "\tRETURNS pg_catalog.varchar\n",
    "\tLANGUAGE javau VOLATILE\n",
    "\tAS 'java.lang.String=com.datarobot.java.Scoring.modelId()'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "select modelId();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `score` function\n",
    "\n",
    "Given the requirement of a sql-ish call to the model, we'll work towards a function that would execute as follows (along with our `modelId()` function)., \n",
    "\n",
    "```\n",
    "select uid, score(feature1, feature2, ...), modelId()\n",
    "from dataset\n",
    "```\n",
    "\n",
    "The syntax below was created by PLJAVA when I packaged up the scoring app.  A simply copy and paste of the syntax and we are ready to go.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "CREATE OR REPLACE FUNCTION score(\n",
    "\tapplication_id integer,\n",
    "\tloan_amnt integer,\n",
    "\tfunded_amnt integer,\n",
    "\tterm pg_catalog.varchar,\n",
    "\tint_rate pg_catalog.varchar,\n",
    "\tint_rate_1 pg_catalog.varchar,\n",
    "\tinstallment double precision,\n",
    "\tgrade pg_catalog.varchar,\n",
    "\tsub_grade pg_catalog.varchar,\n",
    "\temp_title pg_catalog.varchar,\n",
    "\temp_length pg_catalog.varchar,\n",
    "\thome_ownership pg_catalog.varchar,\n",
    "\tannual_inc pg_catalog.varchar,\n",
    "\tverification_status pg_catalog.varchar,\n",
    "\tpymnt_plan pg_catalog.varchar,\n",
    "\turl pg_catalog.varchar,\n",
    "\tdescription pg_catalog.varchar,\n",
    "\tpurpose pg_catalog.varchar,\n",
    "\ttitle pg_catalog.varchar,\n",
    "\tzip_code pg_catalog.varchar,\n",
    "\taddr_state pg_catalog.varchar,\n",
    "\tdti double precision,\n",
    "\tdelinq_2yrs pg_catalog.varchar,\n",
    "\tearliest_cr_line pg_catalog.varchar,\n",
    "\tinq_last_6mths pg_catalog.varchar,\n",
    "\tmths_since_last_delinq pg_catalog.varchar,\n",
    "\tmths_since_last_record pg_catalog.varchar,\n",
    "\topen_acc pg_catalog.varchar,\n",
    "\tpub_rec pg_catalog.varchar,\n",
    "\trevol_bal integer,\n",
    "\trevol_util pg_catalog.varchar,\n",
    "\ttotal_acc pg_catalog.varchar,\n",
    "\tinitial_list_status pg_catalog.varchar,\n",
    "\tmths_since_last_major_derog pg_catalog.varchar,\n",
    "\tpolicy_code integer,\n",
    "\tis_bad integer)\n",
    "\tRETURNS double precision\n",
    "\tLANGUAGE javau VOLATILE\n",
    "\tAS 'double=com.datarobot.java.Scoring.score(int,int,int,java.lang.String,java.lang.String,java.lang.String,double,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,double,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,int)'\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "select application_id, score(\n",
    "  application_id,\n",
    "  loan_amnt,\n",
    "  funded_amnt,\n",
    "  term,\n",
    "  int_rate,\n",
    "  int_rate_1,\n",
    "  installment,\n",
    "  grade,\n",
    "  sub_grade,\n",
    "  emp_title,\n",
    "  emp_length,\n",
    "  home_ownership,\n",
    "  annual_inc,\n",
    "  verification_status,\n",
    "  pymnt_plan,\n",
    "  url,\n",
    "  description,\n",
    "  purpose,\n",
    "  title,\n",
    "  zip_code,\n",
    "  addr_state,\n",
    "  dti,\n",
    "  delinq_2yrs,\n",
    "  earliest_cr_line ,\n",
    "  inq_last_6mths ,\n",
    "  mths_since_last_delinq ,\n",
    "  mths_since_last_record ,\n",
    "  open_acc ,\n",
    "  pub_rec ,\n",
    "  revol_bal ,\n",
    "  revol_util,\n",
    "  total_acc ,\n",
    "  initial_list_status ,\n",
    "  mths_since_last_major_derog ,\n",
    "  policy_code,\n",
    "  is_bad ), modelId()\n",
    "from lending_club limit 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `batchScore` function\n",
    "\n",
    "Nothing much to this in postgres function, but the implementation in java makes it feel very rigid.  The `batchScore` function could take as an argument a string reference a table, which may be a nightly snapshot of the scoring dataset. The function queries data and process the resulting result set and returns a set of complex types.  Complex types is use to describe what may be interpreted as a tuple of differing types.\n",
    "\n",
    "For example my `batchScore` function returns set of `scoredRecord`s.  Each scored record has an `int` ID, a `double` score and a long `time`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "drop function batchScore cascade;\n",
    "drop type scoredRecord cascade;\n",
    "create type scoredRecord as (id int, score double precision, time bigint);\n",
    "\n",
    "CREATE OR REPLACE FUNCTION batchScore(pg_catalog.varchar)\n",
    "\tRETURNS SETOF scoredRecord\n",
    "\tLANGUAGE javau VOLATILE\n",
    "\tAS 'com.datarobot.java.BatchScoring.batchScore(java.lang.String)';"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "-- create snapshot of table\n",
    "drop table temp_snapshot;\n",
    "create table temp_snapshot as \n",
    "SELECT application_id,loan_amnt,funded_amnt,term,int_rate,installment,grade,sub_grade,emp_title,emp_length,home_ownership,annual_inc,verification_status,pymnt_plan,url,description as desc,purpose,title,zip_code,addr_state,dti,delinq_2yrs,earliest_cr_line,inq_last_6mths,mths_since_last_delinq,mths_since_last_record,open_acc,pub_rec,revol_bal,revol_util,total_acc,initial_list_status,mths_since_last_major_derog,cast(policy_code as varchar) as policy_code,is_bad,int_rate_1 from lending_club limit 1000\n",
    ";"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "--- score a snapshot of 1000 records\n",
    "select * from batchScore('temp_snapshot');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%pgsql\n",
    "select avg(time) as avg_time, sum(time) as sum_time, max(time) as max_time, min(time) as min_time from scored_data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does it look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "package com.datarobot.java;\n",
    "\n",
    "import com.datarobot.prediction.IClassificationPredictor;\n",
    "import com.datarobot.prediction.Predictors;\n",
    "\n",
    "import org.postgresql.pljava.annotation.Function;\n",
    "import org.postgresql.pljava.ResultSetProvider;\n",
    "\n",
    "import java.sql.Connection;\n",
    "import java.sql.DriverManager;\n",
    "import java.sql.ResultSet;\n",
    "import java.sql.ResultSetMetaData;\n",
    "import java.sql.SQLException;\n",
    "import java.sql.Statement;\n",
    "import java.sql.Timestamp;\n",
    "\n",
    "import java.util.Iterator;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Map;\n",
    "import java.util.HashMap;\n",
    "\n",
    "public class BatchScoring implements ResultSetProvider\n",
    "{\n",
    "\n",
    "  private String jdbcUrl = \"jdbc:postgresql://localhost:5432/postgres\";\n",
    "  private String username = \"timothy.whittaker\";\n",
    "  private String password = \"postgres\";\n",
    "  private String query;\n",
    "  private Statement stmt = DriverManager.getConnection(jdbcUrl, username, password).createStatement();\n",
    "  \n",
    "  ResultSet rs;\n",
    "  ResultSetMetaData md;\n",
    "  int columnCount;\n",
    "\n",
    "  // LinkedHashMap<String, Object> row\n",
    "\n",
    "  static IClassificationPredictor predictor = Predictors.getPredictor(\"5d5da72a3fa59e2850f824fc\");\n",
    "\n",
    "  public BatchScoring(String table) throws SQLException\n",
    "  {\n",
    "    query = String.format(\"SELECT * from %s\", table);\n",
    "    rs = stmt.executeQuery(query);\n",
    "    md = rs.getMetaData();\n",
    "    columnCount = md.getColumnCount();\n",
    "  }\n",
    "\n",
    " public boolean assignRowValues(ResultSet receiver, int currentRow) throws SQLException {\n",
    "   if(!rs.next())\n",
    "    return false;\n",
    "\n",
    "    Map<String, Object> row = new HashMap<>();\n",
    "    for (int i = 1; i <= columnCount; ++i) {\n",
    "         row.put(md.getColumnName(i), rs.getObject(i));\n",
    "    }\n",
    "    Map<String, Double> class_probabilities = predictor.score(row);\n",
    "\n",
    "   receiver.updateInt(1, rs.getInt(1));\n",
    "   receiver.updateDouble(2, class_probabilities.get(\"1\"));\n",
    "   return true;\n",
    " }\n",
    "\n",
    "  public void close() throws SQLException\n",
    "  {\n",
    "   rs.close();\n",
    "  }\n",
    "  \n",
    "  @Function(type=\"scoredRecord\")\n",
    "  public static ResultSetProvider batchScore(String table)\n",
    "  throws SQLException\n",
    "  {\n",
    "    return new BatchScoring(table);\n",
    "  }\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import com.datarobot.prediction.IClassificationPredictor;\n",
    "import com.datarobot.prediction.Predictors;\n",
    "import java.util.HashMap;\n",
    "import org.postgresql.pljava.annotation.Function;\n",
    "\n",
    "object Scoring { \n",
    "    \n",
    "    val predictor: IClassificationPredictor = Predictors.getPredictor(\"5d5da72a3fa59e2850f824fc\")\n",
    "    \n",
    "    @Function\n",
    "    def modelId(): String = { \n",
    "        predictor.getModelId\n",
    "    }\n",
    "    \n",
    "    @Function\n",
    "    def score(\n",
    "      application_id: Int,\n",
    "      loan_amnt: Int,\n",
    "      funded_amnt: Int,\n",
    "      term: String,\n",
    "      int_rate: String,\n",
    "      int_rate_1: String,\n",
    "      installment: Double,\n",
    "      grade: String,\n",
    "      sub_grade: String,\n",
    "      emp_title: String,\n",
    "      emp_length: String,\n",
    "      home_ownership: String,\n",
    "      annual_inc: String,\n",
    "      verification_status: String,\n",
    "      pymnt_plan: String,\n",
    "      url: String,\n",
    "      description: String,\n",
    "      purpose: String,\n",
    "      title: String,\n",
    "      zip_code: String,\n",
    "      addr_state: String,\n",
    "      dti: Double,\n",
    "      delinq_2yrs: String,\n",
    "      earliest_cr_line: String ,\n",
    "      inq_last_6mths: String ,\n",
    "      mths_since_last_delinq: String ,\n",
    "      mths_since_last_record: String ,\n",
    "      open_acc: String ,\n",
    "      pub_rec: String ,\n",
    "      revol_bal: Int ,\n",
    "      revol_util: String,\n",
    "      total_acc: String ,\n",
    "      initial_list_status: String ,\n",
    "      mths_since_last_major_derog: String ,\n",
    "      policy_code: Int,\n",
    "      is_bad: Int\n",
    "    ): Double = {\n",
    "       \n",
    "       val row = new HashMap[String, Any]()\n",
    "\n",
    "       row.put(\"application_id\",application_id)\n",
    "       row.put(\"loan_amnt\",loan_amnt)\n",
    "       row.put(\"funded_amnt\",funded_amnt)\n",
    "       row.put(\"term\",term)\n",
    "       row.put(\"int_rate\",int_rate)\n",
    "       row.put(\"int_rate_1\",int_rate_1)\n",
    "       row.put(\"installment\",installment)\n",
    "       row.put(\"grade\",grade)\n",
    "       row.put(\"sub_grade\",sub_grade)\n",
    "       row.put(\"emp_title\",emp_title)\n",
    "       row.put(\"emp_length\",emp_length)\n",
    "       row.put(\"home_ownership\",home_ownership)\n",
    "       row.put(\"annual_inc\",annual_inc)\n",
    "       row.put(\"verification_status\",verification_status)\n",
    "       row.put(\"pymnt_plan\",pymnt_plan)\n",
    "       row.put(\"url\",url)\n",
    "       row.put(\"desc\",description)\n",
    "       row.put(\"purpose\",purpose)\n",
    "       row.put(\"title\",title)\n",
    "       row.put(\"zip_code\",zip_code)\n",
    "       row.put(\"addr_state\",addr_state)\n",
    "       row.put(\"dti\",dti)\n",
    "       row.put(\"delinq_2yrs\",delinq_2yrs)\n",
    "       row.put(\"earliest_cr_line\",earliest_cr_line)\n",
    "       row.put(\"inq_last_6mths\",inq_last_6mths)\n",
    "       row.put(\"mths_since_last_delinq\",mths_since_last_delinq)\n",
    "       row.put(\"mths_since_last_record\",mths_since_last_record)\n",
    "       row.put(\"open_acc\",open_acc)\n",
    "       row.put(\"pub_rec\",pub_rec)\n",
    "       row.put(\"revol_bal\",revol_bal)\n",
    "       row.put(\"revol_util\",revol_util)\n",
    "       row.put(\"total_acc\",total_acc)\n",
    "       row.put(\"initial_list_status\",initial_list_status)\n",
    "       row.put(\"mths_since_last_major_derog\",mths_since_last_major_derog)\n",
    "       row.put(\"policy_code\", Integer.toString(policy_code))\n",
    "\n",
    "       val class_probabilities = predictor.score(row);\n",
    "    \n",
    "       class_probabilities.get(\"1\")\n",
    "        \n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val data = scala.io.Source.fromFile(\"/Users/timothy.whittaker/Desktop/sbt-projects/dr-gp-scoring/data/10K_Lending_Club_Loans.txt\").getLines\n",
    "val columns = data.next.split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for( i <- 0 to 10 ) { \n",
    "    val values = data.next.split(\"\\t\")\n",
    "    val application_id:java.lang.Integer = values(0).toInt\n",
    "    val loan_amnt:java.lang.Integer = values(1).toInt\n",
    "    val funded_amnt:java.lang.Integer = values(2).toInt\n",
    "    val term:String = values(3)\n",
    "    val int_rate:String = values(4)\n",
    "    val int_rate_1:String = values(5)\n",
    "    val installment:java.lang.Double = values(6).toDouble\n",
    "    val grade:String = values(7)\n",
    "    val sub_grade:String = values(8)\n",
    "    val emp_title:String = values(9)\n",
    "    val emp_length:String = values(10)\n",
    "    val home_ownership:String = values(11)\n",
    "    val annual_inc:String = values(12)\n",
    "    val verification_status:String = values(13)\n",
    "    val pymnt_plan:String = values(14)\n",
    "    val url:String = values(15)\n",
    "    val description:String = values(16)\n",
    "    val purpose:String = values(17)\n",
    "    val title:String = values(18)\n",
    "    val zip_code:String = values(19)\n",
    "    val addr_state:String = values(20)\n",
    "    val dti:java.lang.Double = values(21).toDouble\n",
    "    val delinq_2yrs:String = values(22)\n",
    "    val earliest_cr_line :String = values(23)\n",
    "    val inq_last_6mths :String = values(24)\n",
    "    val mths_since_last_delinq :String = values(25)\n",
    "    val mths_since_last_record :String = values(26)\n",
    "    val open_acc :String = values(27)\n",
    "    val pub_rec :String = values(28)\n",
    "    val revol_bal :java.lang.Integer = values(29).toInt\n",
    "    val revol_util:String = values(30)\n",
    "    val total_acc :String = values(31)\n",
    "    val initial_list_status :String = values(32)\n",
    "    val mths_since_last_major_derog :String = values(33)\n",
    "    val policy_code:java.lang.Integer = values(34).toInt\n",
    "    val is_bad :java.lang.Integer = values(35).toInt\n",
    "\n",
    "    val score = Scoring.score(\n",
    "        application_id,\n",
    "        loan_amnt,\n",
    "        funded_amnt,\n",
    "        term,\n",
    "        int_rate,\n",
    "        int_rate_1,\n",
    "        installment,\n",
    "        grade,\n",
    "        sub_grade,\n",
    "        emp_title,\n",
    "        emp_length,\n",
    "        home_ownership,\n",
    "        annual_inc,\n",
    "        verification_status,\n",
    "        pymnt_plan,\n",
    "        url,\n",
    "        description,\n",
    "        purpose,\n",
    "        title,\n",
    "        zip_code,\n",
    "        addr_state,\n",
    "        dti,\n",
    "        delinq_2yrs,\n",
    "        earliest_cr_line ,\n",
    "        inq_last_6mths ,\n",
    "        mths_since_last_delinq ,\n",
    "        mths_since_last_record ,\n",
    "        open_acc ,\n",
    "        pub_rec ,\n",
    "        revol_bal ,\n",
    "        revol_util,\n",
    "        total_acc ,\n",
    "        initial_list_status ,\n",
    "        mths_since_last_major_derog ,\n",
    "        policy_code,\n",
    "        is_bad )\n",
    "\n",
    "    println(f\"application id ${application_id} has a default score of ${score}%2.2f based on model ${Scoring.modelId}\")\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
